{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "RNN-task.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivarbratberg/intro-to-dl/blob/master/week5/RNN-task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fePMGTWBcJAU",
        "colab_type": "code",
        "outputId": "27a15cb4-13f1-4705-f43c-3e0386ecbb1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x\n",
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week2_honor()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "--2020-05-28 14:19:54--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-28 14:19:54 (55.3 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8joFNY6RbOmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6q43K4McHz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybzEG9kvbOmJ",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "L_Lbkvn3bOmK",
        "colab_type": "code",
        "outputId": "61356ff3-26dd-4dac-eacf-a9cc7ec15f1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMyOOamBbOmN",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "uZ-fgkPQbOmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "jq7LQMaTbOmR",
        "colab_type": "code",
        "outputId": "10f23bd9-e0a0-4594-8dd9-46c9111dfa9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "1iiJsOYKbOmV",
        "colab_type": "code",
        "outputId": "4a0a98a4-df0c-47f2-d7c2-00c763acd6b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGYvlsWzbOmY",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "3wqOxJZjbOmY",
        "colab_type": "code",
        "outputId": "fec0e4ac-7df2-4008-e53f-6f3cde448a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "#all unique characters go here\n",
        "tokens = set(''.join(names))\n",
        "\n",
        "tokens = list(tokens)\n",
        "tokens.append(pad_token)\n",
        "\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens = ',n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens =  56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxB6Kg7ebOmd",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "WCVjqVGZbOme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0c2df262-bbe1-49a9-acd4-ef22fa7cd0e5"
      },
      "source": [
        "token_to_id = {symbol : index for symbol,index in zip(tokens,range(len(tokens)))}\n",
        "###YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens }\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
        "print(token_to_id)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Q': 0, 'U': 1, 'e': 2, 'D': 3, 'v': 4, 'g': 5, ' ': 6, 'q': 7, 't': 8, 'b': 9, 's': 10, 'Y': 11, 'P': 12, 'x': 13, 'l': 14, 'm': 15, 'R': 16, '-': 17, 'J': 18, 'V': 19, 'c': 20, 'C': 21, 'Z': 22, 'K': 23, 'F': 24, 'B': 25, 'G': 26, 'z': 27, 'L': 28, 'y': 29, 'd': 30, 'M': 31, 'S': 32, 'T': 33, 'h': 34, 'W': 35, 'u': 36, 'p': 37, 'H': 38, 'X': 39, 'O': 40, 'r': 41, 'i': 42, 'E': 43, 'k': 44, 'A': 45, \"'\": 46, 'o': 47, 'f': 48, 'I': 49, 'N': 50, 'n': 51, 'j': 52, 'w': 53, 'a': 54, '#': 55}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "vwcdISAIbOmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "0-MMz6QvbOmk",
        "colab_type": "code",
        "outputId": "d0d55bc2-f3a1-4cae-901a-056d9503f340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 6 45  9 54  5 54  2 14 55]\n",
            " [ 6 26 14 47 41 29 55 55 55]\n",
            " [ 6 12 41 42 10 10 42  2 55]\n",
            " [ 6 26 42 47  4 54 51 51  2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUPcPS2qbOmm",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/ivarbratberg/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "tkKT1jmhbOmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "q3K3WHmXbOmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "### YOUR CODE HERE\n",
        "\n",
        "get_h_next = Dense(rnn_num_units, activation='tanh')\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "### YOUR CODE HERE \n",
        "get_probas = Dense(n_tokens, activation = 'softmax')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jFCmk3LbOmu",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/ivarbratberg/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "ERpd-Gt7bOmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    #  ## YOUR CODE HERE\n",
        "    x_and_h = concatenate([x_t_emb, h_t])\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    ### YOUR CODE HERE\n",
        "    h_next = get_h_next(x_and_h)\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    ### YOUR CODE HERE\n",
        "    output_probas = get_probas(h_next)\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2JqpuCNbOmx",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "QBxtSkjGbOmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU7LZAHcoys2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "aa792712-4bd6-4920-f404-7d5b7a5db9a3"
      },
      "source": [
        "import numpy as np\n",
        "a = np.random.rand(3,3)\n",
        "print(a)\n",
        "print(a[:,:-1])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.38717043 0.52007813 0.9625249 ]\n",
            " [0.93932332 0.2040593  0.65760432]\n",
            " [0.3021266  0.89041928 0.15562938]]\n",
            "[[0.38717043 0.52007813]\n",
            " [0.93932332 0.2040593 ]\n",
            " [0.3021266  0.89041928]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFJnYb4kbOm1",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "ebvAWDvnbOm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRaW7ZnnzOdr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "cacfca32-e606-4c70-ce61-b5292d4987b1"
      },
      "source": [
        "import tensorboard\n",
        "print(input_sequence.shape)\n",
        "print(predictions_matrix.shape)\n",
        "print(answers_matrix.shape)\n",
        "print(n_tokens)\n",
        "# answers_matrix.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 16)\n",
            "(?, 56)\n",
            "(?, 56)\n",
            "56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQs2k771bOm4",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSP70ETj0KkB",
        "colab_type": "text"
      },
      "source": [
        "## Loss\n",
        "SoftMax will give prob(class) exp(class_i)/sum(class_...)\n",
        "Cross Entropy loss will be sum og props when not belonging to this class\n",
        "The logit function is what is calculated from the dense function\n",
        "\n",
        "### Variables used\n",
        "answer_matrix contains probabillities for each, that means 1 for the predicedt and 0 for the rest\n",
        "predictions_matrix contains predictions for al\n",
        "\n",
        "## Training\n",
        "We take a batches and feed it and for each batch the weights are trained\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "v3ZJGn5tbOm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "### YOUR CODE HERE\n",
        "from keras.losses import categorical_crossentropy\n",
        "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix))\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_51rCPBkbOm7",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "Xq7sLf06bOm8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f6509ff4-1c7d-4d77-aaa2-04c810c1883a"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        " \n",
        "s.run(tf.global_variables_initializer())\n",
        "# s.run( tf.initialize_all_variables())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtY0m9NPbOnA",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "L1zncdibbOnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "6q0efZFabOnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "ND5VVBQFbOnG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "b8a8e561-f90b-4c4a-d8fa-7aef764ad329"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Sonsla\n",
            " Rusy\n",
            " Katemer\n",
            " Ragreli\n",
            " HIlpal\n",
            " Dlaldyrls\n",
            " Mirtha\n",
            " Har\n",
            " Darhyr\n",
            " Naminrde\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "BacNGhq_bOnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "fc7eca5d-3a2f-4352-8162-0b344e1698c1"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpi\n",
            " Trumpes\n",
            " Trumpinge\n",
            " Trumpe\n",
            " Trumpa\n",
            " Trumpke\n",
            " Trumpeld\n",
            " Trump\n",
            " Trumpa\n",
            " Trumpile\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju-alKnAbOnK",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "VJ6y-GlMbOnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"### YOUR TOKEN HERE ###\"\n",
        "COURSERA_EMAIL = \"### YOUR EMAIL HERE ###\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "Ch1qFBN2bOnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukIICOa8bOnQ",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "DPjj1kcTbOnQ",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "lk24xFiMbOnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq1x_8ZUbOnT",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "mQPOuo1HbOnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "OnMh_5crbOnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}